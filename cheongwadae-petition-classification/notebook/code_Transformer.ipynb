{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4402e135-c37e-4357-9f10-c5ff803e680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soyspacing in c:\\users\\epdls\\anaconda3\\lib\\site-packages (1.0.17)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from soyspacing) (1.22.4)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install soyspacing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b3dc75-f023-47aa-bcea-edea9a8d8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from konlpy.tag import Mecab\n",
    "from soyspacing.countbase import CountSpace\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5bdc14-441e-40f5-8cdf-87a6b0a72f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fdd9caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7988423307366511196\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 22718447616\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 17481597131432050140\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:02:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d912ea-74fc-4940-a770-5b8a5a7ee47b",
   "metadata": {},
   "source": [
    "### **데이터 읽기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386f4662-379e-4631-9b3c-f36687d97d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv').iloc[:, 1:]\n",
    "test = pd.read_csv('./test.csv').iloc[:, 1:]\n",
    "submission = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65789859-e55b-4aff-82d3-c317262f2932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>학교이름에 '남자'도 붙여주세요. 울산여자중학교에 재학중인 학생입니다 최근 양성평등...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>빙상연맹, 대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요.. 최근 동계올...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>티비 12세,15세 관람가도 연령확인 의무화 하자.. 제기 에전에 티비를 보다가 잠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>무더운 여름철엔 남성들도 시원한 자율복장을 해야. 무더운 여름철에는 남성들도 노넥타...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               data\n",
       "0         2  신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지...\n",
       "1         0  학교이름에 '남자'도 붙여주세요. 울산여자중학교에 재학중인 학생입니다 최근 양성평등...\n",
       "2         1  빙상연맹, 대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요.. 최근 동계올...\n",
       "3         1  티비 12세,15세 관람가도 연령확인 의무화 하자.. 제기 에전에 티비를 보다가 잠...\n",
       "4         1  무더운 여름철엔 남성들도 시원한 자율복장을 해야. 무더운 여름철에는 남성들도 노넥타..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c5e23-69f5-453c-b819-abbca7e8c7f8",
   "metadata": {},
   "source": [
    "### **전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af3436b-e848-49b1-b6b2-a9b9c1c7ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5263342a-a32d-45ac-9421-a856f727a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','에서', '만', '뿐', '조차', '마저', '까지', '와','한','하다','을']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "604f3290-14bb-4911-bfd8-ceda0cde7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['data'] = train['data'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', regex=True)\n",
    "test['data'] = test['data'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edf249ed-3684-4cc5-8f70-3f7d6fe45a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_text = [word.strip() for word in train['data'] if not word in stopwords]\n",
    "cleaned_test_text = [word.strip() for word in test['data'] if not word in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa294d-96fe-4f8e-882d-2e9d88332efa",
   "metadata": {},
   "source": [
    "### **토큰화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0709255a-cb6d-45de-9c7a-4e5edccc0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab(dicpath=r\"C:\\mecab\\mecab-ko-dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f031e10-d121-49e6-8144-e2bd9e97257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████▉| 39991/39992 [00:22<00:00, 1744.43it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "\n",
    "for sentence, i in zip(train['data'], tqdm(range(len(train['data'])))) :\n",
    "    temp_X = []\n",
    "    temp_X = mecab.nouns(sentence)\n",
    "    temp_X = [word for word in temp_X if not word in stopwords]\n",
    "    X_train.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d9028b2-ea7b-4951-ae34-9173a9422594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 4999/5000 [00:02<00:00, 1746.40it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "\n",
    "for sentence, i in zip(test['data'], tqdm(range(len(test['data'])))) :\n",
    "    temp_X = []\n",
    "    temp_X = mecab.nouns(sentence)\n",
    "    temp_X = [word for word in temp_X if not word in stopwords]\n",
    "    X_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1cfeded-19a6-41be-9679-9c7fa7360608",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcbc6ead-19aa-4d44-b6bf-83c0e69defce",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30000 # 39992개 단어 중 출현 빈도가 상위 VOCAB_SIZE개에 속하는 것만 사용하도록 설정\n",
    "MAX_LEN = 350\n",
    "\n",
    "tokenizer = Tokenizer(VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(X_train) # fit_on_texts: 문자 데이터를 입력받아 리스트 형태로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c332f77-08ed-4ade-a41b-41155bdd61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a359341b-e92d-44be-aa4b-3c4fcbe77426",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=MAX_LEN)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7fff39e-c34c-41f7-9ab6-a85ab54137f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   72, 1776, 7064],\n",
       "       [   0,    0,    0, ...,    7,   18,  131],\n",
       "       [   0,    0,    0, ...,  187, 1013,    2],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4,  449,   33],\n",
       "       [   0,    0,    0, ...,    2,   50,  307],\n",
       "       [   0,    0,    0, ...,  189,  933,  327]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35f3a88d-50d7-4243-b8b4-3b7e5c5cd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(train['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4955842-de1e-4c05-96ec-0fa1810b645c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e3547-cddb-470e-8e3b-6962805928aa",
   "metadata": {},
   "source": [
    "### **모델링(Transformer)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160fd93a",
   "metadata": {},
   "source": [
    "데이콘 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67e449dc-0be5-4b0f-892f-8f34e6526295",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6afcdbd-a21a-4a44-a891-0a3e9bb089c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, embedding_dim, num_heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim # d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embedding_dim % self.num_heads == 0\n",
    "\n",
    "        self.projection_dim = embedding_dim // num_heads\n",
    "        self.query_dense = Dense(embedding_dim)\n",
    "        self.key_dense = Dense(embedding_dim)\n",
    "        self.value_dense = Dense(embedding_dim)\n",
    "        self.dense = Dense(embedding_dim)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embedding_dim' : self.embedding_dim,\n",
    "            'num_heads' : self.num_heads,\n",
    "            \n",
    "            'projection_dim' : self.projection_dim,\n",
    "            'query_dense' : self.query_dense,\n",
    "            'key_dense' : self.key_dense,\n",
    "            'value_dense' : self.value_dense,\n",
    "            'dense' : self.dense\n",
    "        })\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        logits = matmul_qk / tf.math.sqrt(depth)\n",
    "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        query = self.split_heads(query, batch_size)  \n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
    "        # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a008fe01-b3aa-42e4-bf79-38a6b0a25571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(embedding_dim, num_heads)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(dff, activation=\"relu\"),\n",
    "             Dense(embedding_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'att' : self.att,\n",
    "            'ffn' : self.ffn,\n",
    "            'layernorm1' : self.layernorm1,\n",
    "            'layernorm2' : self.layernorm2,\n",
    "            'dropout1' : self.dropout1,\n",
    "            'dropout2' : self.dropout2\n",
    "        })\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fb3aa2d-9658-45e3-8442-170c9d25f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_emb = Embedding(max_len, embedding_dim)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'token_emb' : self.token_emb,\n",
    "            'pos_emb' : self.pos_emb,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, x):\n",
    "        max_len = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a05ab940-0842-4404-9034-f16ec9c84cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32  # Embedding size for each token\n",
    "num_heads = 4  # Number of attention heads\n",
    "dff = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = Input(shape=(MAX_LEN,))\n",
    "embedding_layer = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE, embedding_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(3, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b64178f6-9c23-4d37-8f57-c9b01140d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "718e324c-767f-4757-b0cd-135ba3e2486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_1 = 'tf_chkpoint.ckpt'\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "mc = ModelCheckpoint(filepath =  os.path.join(path, ckpt_1), monitor = 'val_accuracy', save_best_only = True, mode = 'max',verbose = 1, save_weights_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, min_delta=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95ab851b-16d2-400c-80ea-ce00cc2023d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 8s 25ms/step - loss: 0.7127 - accuracy: 0.6683 - val_loss: 0.3605 - val_accuracy: 0.8715\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.87148, saving model to ./model\\tf_chkpoint.ckpt\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.3536 - accuracy: 0.8655 - val_loss: 0.3433 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.87148\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.2706 - accuracy: 0.9009 - val_loss: 0.3281 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.87148 to 0.87923, saving model to ./model\\tf_chkpoint.ckpt\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.2210 - accuracy: 0.9188 - val_loss: 0.3775 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.87923\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.1768 - accuracy: 0.9355 - val_loss: 0.4433 - val_accuracy: 0.8609\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.87923\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.1430 - accuracy: 0.9432 - val_loss: 0.5500 - val_accuracy: 0.8547\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.87923\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.1213 - accuracy: 0.9521 - val_loss: 0.6556 - val_accuracy: 0.8491\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.87923\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.1080 - accuracy: 0.9571 - val_loss: 0.6981 - val_accuracy: 0.8427\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.87923\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.0924 - accuracy: 0.9634 - val_loss: 0.7501 - val_accuracy: 0.8415\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.87923\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.0842 - accuracy: 0.9649 - val_loss: 0.7847 - val_accuracy: 0.8404\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.87923\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.0810 - accuracy: 0.9664 - val_loss: 0.8933 - val_accuracy: 0.8334\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.87923\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.0797 - accuracy: 0.9664 - val_loss: 0.9308 - val_accuracy: 0.8406\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87923\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.0700 - accuracy: 0.9703 - val_loss: 0.9372 - val_accuracy: 0.8371\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.87923\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.0661 - accuracy: 0.9718 - val_loss: 0.9326 - val_accuracy: 0.8309\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.87923\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.0633 - accuracy: 0.9715 - val_loss: 1.0325 - val_accuracy: 0.8320\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.87923\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.0603 - accuracy: 0.9736 - val_loss: 1.1322 - val_accuracy: 0.8302\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.87923\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.0545 - accuracy: 0.9752 - val_loss: 1.1554 - val_accuracy: 0.8309\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.87923\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.0546 - accuracy: 0.9750 - val_loss: 1.1917 - val_accuracy: 0.8264\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.87923\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.0542 - accuracy: 0.9753 - val_loss: 1.1921 - val_accuracy: 0.8319\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.87923\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.0504 - accuracy: 0.9763 - val_loss: 1.2851 - val_accuracy: 0.8271\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.87923\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.0506 - accuracy: 0.9757 - val_loss: 1.2566 - val_accuracy: 0.8299 3s - l - ETA: 2s - los - ETA: 1s - loss: 0.0484 -  - ETA: 0s - loss: 0.0\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.87923\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.0489 - accuracy: 0.9774 - val_loss: 1.3014 - val_accuracy: 0.8299\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.87923\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.0497 - accuracy: 0.9769 - val_loss: 1.3066 - val_accuracy: 0.8272\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.87923\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    history = model.fit(X_train, y_train, batch_size=128, epochs=, validation_split=0.2, callbacks = [mc, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9ccaf3a-d88f-4605-bc4c-0f6f18837e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a1a2cdd-5484-46c6-b7ec-cbd144b5e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['category'] = np.argmax(y_pred, axis=-1)\n",
    "submission.to_csv('./submission.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a148498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
