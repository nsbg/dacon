{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff61b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\epdls\\anaconda3\\lib\\site-packages (4.20.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: requests in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from requests->transformers) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\epdls\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\epdls\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28755e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import trange\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertModel\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd51b66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3ebd14",
   "metadata": {},
   "source": [
    "### 데이터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5994ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset/train.csv')\n",
    "test = pd.read_csv('./dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313aca63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>채소가 약간 시들어 있어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>발톱 두껍고 단단한 분들 써도 소용없어요 이 테이프 물렁거리고 힘이없어서 들어 올리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>부들부들 좋네요 입어보고 시원하면 또 살게요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>이런 1. 8 골드 주라니깐 파란개 오네 회사전화걸어도 받지도 않고 머하자는거임?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>검수도 없이 보내구 불량 배송비 5000원 청구하네요 완전별로 별하나도 아까워요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>사용해보니 좋아요~^^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>저렴한가격에. 질좋고. 핏좋고. 너무. 이쁘게. 입고다녀요..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>세트상품이라고 써있어서 그런줄 알고 구매했더니 단품이었네요 낚인 느낌도 들고 그러네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>역시 로네펠트!! 좋아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>데싱 디바 써보고 갠찮아서 비슷 한줄 알앗더니 완전 별로예요ㅡㅡ3000언 더주고 디...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            reviews\n",
       "0          0                                     채소가 약간 시들어 있어요\n",
       "1          1  발톱 두껍고 단단한 분들 써도 소용없어요 이 테이프 물렁거리고 힘이없어서 들어 올리...\n",
       "2          2                           부들부들 좋네요 입어보고 시원하면 또 살게요\n",
       "3          3      이런 1. 8 골드 주라니깐 파란개 오네 회사전화걸어도 받지도 않고 머하자는거임?\n",
       "4          4       검수도 없이 보내구 불량 배송비 5000원 청구하네요 완전별로 별하나도 아까워요\n",
       "...      ...                                                ...\n",
       "24995  24995                                       사용해보니 좋아요~^^\n",
       "24996  24996                 저렴한가격에. 질좋고. 핏좋고. 너무. 이쁘게. 입고다녀요..\n",
       "24997  24997  세트상품이라고 써있어서 그런줄 알고 구매했더니 단품이었네요 낚인 느낌도 들고 그러네...\n",
       "24998  24998                                     역시 로네펠트!! 좋아요.\n",
       "24999  24999  데싱 디바 써보고 갠찮아서 비슷 한줄 알앗더니 완전 별로예요ㅡㅡ3000언 더주고 디...\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825aed9",
   "metadata": {},
   "source": [
    "### 토크나이저 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c26e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f941c2e1",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de37f5dc",
   "metadata": {},
   "source": [
    "#### 1) 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9151d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train = []\n",
    "clean_test = []\n",
    "\n",
    "for train_txt, test_txt in zip(train.reviews, test.reviews):\n",
    "    clean_train.append(re.sub('[^가-힣ㄱ-하-ㅣ\\\\s]', ' ', train_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac5d1eb",
   "metadata": {},
   "source": [
    "#### 2) 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "206dc8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_add_token = ['[CLS] '+s+' [SEP]' for s in clean_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f183083",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = [tokenizer.tokenize(i) for i in train_add_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb32c18",
   "metadata": {},
   "source": [
    "### 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3425df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(i) for i in tokenized_train]\n",
    "\n",
    "len_check = []\n",
    "\n",
    "for i in input_ids:\n",
    "    len_check.append(len(i))\n",
    "\n",
    "max(len_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "369132e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128 # default\n",
    "\n",
    "input_ids= pad_sequences(input_ids, maxlen=MAX_LEN, truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f8af56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,   9678,  16985,  48549,  62849,  17196,  58303,   9496,\n",
       "        14153, 119423,  12965,  48549,    102,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71616002",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = []\n",
    "\n",
    "for ids in input_ids:\n",
    "    seq_mask = [float(i>0) for i in ids]\n",
    "    attention_mask.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "180ea693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c632815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, train['target'].values, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef54168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, validation_mask, _, _ = train_test_split(attention_mask, input_ids, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53105cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-d81954d0c755>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Size mismatch between tensors\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = TensorDataset(torch.tensor(train_inputs), torch.tensor(train_labels), torch.tensor(train_mask))\n",
    "train_data = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_data = TensorDataset(torch.tensor(validation_inputs), torch.tensor(validation_labels), torch.tensor(validation_mask))\n",
    "validation_data = DataLoader(validation_data, sampler=RandomSampler(validation_data), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27da0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3af78aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18750, 128)\n",
      "(18750,)\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs.shape)\n",
    "print(train_labels.shape)\n",
    "print(len(train_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec112ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c158cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "epochs = 20\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 반복\n",
    "for epoch_i in trange(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015457d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
